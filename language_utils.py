import torch
from utils import Embedding
import wordnet_utils
from nltk.corpus import wordnet as wn
import numpy as np
import networkx as nx
import matplotlib.pyplot as plt
import math
import seaborn as sns
import colorcet as cc
from PIL import Image, ImageDraw

class ConceptModel:

    def __init__(self, embedding: Embedding, dict_path, filter_dict=True):
        self.embedding = embedding
        self.target_synset = wn.synsets('entity', pos=wn.NOUN)[0]
        if isinstance(dict_path, str):
            dict_all = self.embedding.load_txt_dict(dict_path)
        else:
            dict_all = dict_path
        if filter_dict:
            filtered_dict = [word for word in dict_all if wordnet_utils.is_word_in_wordnet(word)]
            self.wn_hierarchy = wordnet_utils.create_graph_to(filtered_dict, self.target_synset, filter=False, with_repeats=True, filter_nonequal_lemmas=False)
            self.filtered_dict = [x for x in filtered_dict if wordnet_utils.has_path_to(x, self.target_synset)]
        else:
            self.filtered_dict = dict_all
        self.dict_len = len(self.filtered_dict)
        self.dict_emb = embedding.get_text_embedding(self.filtered_dict).cpu().numpy()
        embedding.set_dict_emb(self.dict_emb)

    def get_embedding_tlcs(self, image_embedding):
        """
        Given an image embedding returns an assignment map of each pixel to the closest concept in the dictionary.
        Also returns the list of unique values in the assignment (the TLCs)
        """
        dict_similarities = self.embedding.get_similarities(image_embedding)  # TODO check whether to add , self.dict_emb
        assignment = np.argmax(dict_similarities, axis=0)
        tlc_image = np.unique(assignment)
        return assignment, tlc_image

    def hierarchy_path_to_root(self, node, hierarchy):
        """
        Given a hierarchy tree, returns all paths from node to the tree root
        :param node:
        :param hierarchy:
        :return:
        """
        open_list = [node]
        open_depth = [0 for x in open_list]
        closed_list = []
        current_path = []
        all_paths = []
        current_node = None

        while open_list:
            # Perform depth-first search
            current_node = open_list.pop()
            closed_list.append(current_node)
            current_depth = open_depth.pop()
            current_path = current_path[0:current_depth] + [current_node]

            try:
                # This is needed if you have an unconnected node to root due to a hypernym not leading to object.n.01
                current_hyper = [a for a, b in hierarchy.in_edges(current_node)]
            except nx.NetworkXError:
                continue
            if not current_hyper:
                all_paths.append(current_path)
            else:
                for hyper in current_hyper:
                    open_list.append(hyper)
                    open_depth.append(len(current_path))

        return all_paths

    def hierarchy_root_to_lemma_tree(self, lemma: str, hierarchy, filter_nonequal_lemmas=False):
        """
        Given a lemma and the wordnet hierarchy, returns a tree containing all and only paths that from the wordnet
        hierarchy root lead to all the synsets of lemma.

        :param lemma: the lemma to build the tree to
        :param hierarchy: the wordnet hierarchy of all concepts in the dict, as generated by create_graph_to
        :param filter_nonequal_lemmas: If true, removes from the tree all paths that lead to a leaf for which the first
        lemma is different from param lemma
        :return: a digraph containing all paths to synsets of lemma, which can be used to build a similarity tree
        """
        tree = nx.DiGraph()
        word_wn = wn.synsets(lemma, pos=wn.NOUN)
        for syn in word_wn:
            # Don't proceed if filter_nonequal_lemmas and the syn name root is not equal to the word
            syn_name_root = syn.name().split('.')[0]
            if filter_nonequal_lemmas and syn_name_root != lemma:
                continue
            paths = self.hierarchy_path_to_root(syn, hierarchy)
            for path in paths:
                for node in path:
                    if not tree.has_node(node):
                        tree.add_node(node)
                for i in range(1, len(path)):
                    tree.add_edge(path[i], path[i - 1])
        return tree

    def similarity_tree_visit_count_decorator(self, tree: nx.DiGraph):
        """
        Given a similarity tree generated with hierarchy_root_to_lemma_tree, decorate it adding to each node the
        attribute "visit_count" and set this to 0
        :param tree:
        :return:
        """
        for node in tree.nodes():
            nx.set_node_attributes(tree, {node: {"visit_count": 0}})
        return tree

    def similarity_tree_update_counts(self, similarity_tree: nx.DiGraph, new_tree: nx.DiGraph):
        """
        Increments attribute 'visit_count' in similarity_tree for each node of similarity_tree that is present also in
        new_tree.
        :param similarity_tree:
        :param new_tree:
        :param concept:
        :return:
        """
        for node in new_tree.nodes():
            if similarity_tree.has_node(node):
                current_count = similarity_tree.nodes[node]['visit_count']
                nx.set_node_attributes(similarity_tree, {node: {"visit_count": current_count + 1}})
        return similarity_tree

    def get_subtree_set(self, tree: nx.DiGraph, node):
        """
        Returns the set of nodes from the subtree starting from node
        :param tree:
        :param node:
        :return:
        """
        # Compute subtree with associated depth
        open_set = [node]
        closed_set = []
        score_list = []
        while open_set:
            current_node = open_set.pop(0)
            if current_node in closed_set:
                continue
            open_set = open_set + [b for a, b in tree.edges(current_node)]
            closed_set = closed_set + [current_node]
        closed_set = set(closed_set)
        return closed_set

    def similarity_tree_subtree_score_decorator(self, tree: nx.DiGraph, aggregator=None, attribute="concept_similarity"):
        """
        Decorates each node of tree with attribute 'subtree_score' which is computed as aggregator(attribute) for all
        nodes in the subtree of the node.

        :param tree:
        :param aggregator: if None leaves it as a list, if callable
        :return:
        """
        for node in tree.nodes():
            subtree = self.get_subtree_set(tree, node)
            if aggregator is None:
                scores = list(set([tree.nodes[x][attribute] for x in list(subtree)]))
            else:
                scores = aggregator([tree.nodes[x][attribute] for x in list(subtree)])
            # scores = get_subtree_depthwise_scores(tree, node)
            nx.set_node_attributes(tree, {node: {"subtree_score": scores}})
        return tree

    def get_concept_similarity_tree(self, image_embedding, assignment, concept_id, k=20):
        """
        Given an image embedding and a concept_id, finds the similarity tree of all synsets of concept[concept_id] with
        the concept average vector found in the image.

        :param image_embedding:
        :param assignment:
        :param concept_id:
        :param k: how many close words to take to compute the tree. Default 20
        :return:
        """

        concept = self.filtered_dict[concept_id]
        # Compute the patch average vector by taking pixels in the image_embedding that are assigned to this TLC
        concept_average_vector = torch.mean(image_embedding[::, assignment == concept_id, ::], dim=[0, 1])
        concept_average_vector = torch.nn.functional.normalize(concept_average_vector, p=2.0, dim=0)

        # Build the network of all paths from this TLC to 'entity'
        similarity_tree = self.hierarchy_root_to_lemma_tree(concept, self.wn_hierarchy)
        similarity_tree = self.similarity_tree_visit_count_decorator(similarity_tree)

        # Sort words by similarity with concept
        concept_dict_similarity = torch.tensordot(concept_average_vector, torch.from_numpy(self.dict_emb).cuda(),
                                                  dims=([0], [1]))
        sorted_similarities, sorted_indices = torch.sort(concept_dict_similarity)
        sorted_similarities = torch.flip(sorted_similarities.view(1, -1), dims=[1]).flatten()
        sorted_indices = torch.flip(sorted_indices.view(1, -1), dims=[1]).flatten()
        # Update counts for first k similar concepts, then draw result
        for i in range(1, k + 1):
            new_concept_id = sorted_indices[i]
            new_concept = self.filtered_dict[new_concept_id]
            new_tree = self.hierarchy_root_to_lemma_tree(new_concept, self.wn_hierarchy)
            similarity_tree = self.similarity_tree_update_counts(similarity_tree, new_tree)

        similarity_tree = self.similarity_tree_subtree_score_decorator(similarity_tree, aggregator=np.sum,
                                                                       attribute="visit_count")

        return similarity_tree

    def similarity_tree_find_best_leaf(self, tree: nx.DiGraph, source_synset, similarity_attribute="subtree_score"):

        max_node = source_synset
        out_nodes = [b for a, b in tree.edges(max_node)]
        # As long as there are children
        while out_nodes:
            # Get lists from node attributes
            path_score_lists = []
            children_similarities = []
            for node in out_nodes:
                try:
                    path_score_lists.append(tree.nodes[node]["subtree_score"])
                except KeyError:
                    pass
                children_similarities.append(tree.nodes[node][similarity_attribute])
            # Determine winner
            max_idx = np.argmax(children_similarities)
            max_node = out_nodes[max_idx]
            out_nodes = [b for a, b in tree.edges(max_node)]

        return max_node

    def is_in_path(self, similarity_tree, leaf, target):
        """
        Returns a boolean indicating whether synset leaf has target as a parent (even inherited)
        :param similarity_tree:
        :param leaf:
        :param target:
        :return:
        """
        # Create parent list by exploration
        open_list = [leaf]
        closed_list = []

        while open_list:
            current_node = open_list.pop()
            if current_node in closed_list:
                continue
            closed_list.append(current_node)
            open_list = open_list + [a for a, b in similarity_tree.in_edges(current_node)]

        return target in closed_list

    def get_image_embedding_concept_mask(self, image_embedding: torch.Tensor, mask_synset):
        """
        Given an embedding of an image (a volume H*W*512) and a concept as a synset (e.g. Synset('animal.n.01'))
        returns a binary mask H*W where each element is 1 iff the corresponding element in image_embedding has a s
        emantic path that passes through 'concept'.

        :param image_embedding: the image embedding as a tensor
        :param mask_synset: the concept as a synset on which the mask is based
        :return: a binary mask of same spatial dimension as image_embedding
        """

        assignment, tlc_image = self.get_embedding_tlcs(image_embedding)

        mask = np.zeros_like(assignment)

        # For each tlc in the image
        for concept_id in tlc_image:
            similarity_tree = self.get_concept_similarity_tree(image_embedding, assignment, concept_id)
            best_syn = self.similarity_tree_find_best_leaf(similarity_tree, self.target_synset)
            if self.is_in_path(similarity_tree, best_syn, mask_synset):
                mask[assignment == concept_id] = 1

        return mask

    def plot_segmentation(self, assignment_map, np_image, alpha=0.2):
        # Map unique values in assignment_map to a range starting from 0
        unique_idxs = np.unique(assignment_map)
        n_idx = unique_idxs.size
        remapped_assigment = np.zeros_like(assignment_map)
        for i in range(n_idx):
            remapped_assigment[assignment_map == unique_idxs[i]] = i
        # Get palette for how many unique concepts there are
        palette = sns.color_palette(cc.glasbey, n_colors=n_idx)
        color_mapped = np.take(palette, remapped_assigment, axis=0)
        # Double size of remapped
        color_mapped = color_mapped.repeat(2, axis=0).repeat(2, axis=1)
        # Center crop image to match size
        np_image = np.transpose(np_image.squeeze(), [1, 2, 0])
        crop_x = np_image.shape[1] - color_mapped.shape[1]
        crop_y = np_image.shape[0] - color_mapped.shape[0]
        np_image = np_image[:-math.floor(crop_y), :-math.floor(crop_x), :]
        legend_image = Image.new("RGB", (200, color_mapped.shape[0]))
        draw = ImageDraw.Draw(legend_image)
        for i in range(n_idx):
            color = tuple([int(x * 255) for x in palette[i]] + [255])
            shape = [(10, 10 + i * 20), (30, 20 + i * 20)]
            draw.rectangle(shape, fill=color)
            draw.text((40, i * 20 + 10), self.filtered_dict[unique_idxs[i]])

        legend_image = np.array(legend_image).astype(float) / 255
        overlay = alpha * np_image + (1 - alpha) * color_mapped
        with_legend = np.concatenate((overlay, legend_image), axis=1)
        plt.figure(figsize=(20, 20))
        plt.imshow(with_legend)
        plt.show()

    def plot_image_assignment(self, img: str):
        # Compute top level concepts in image
        k = 20
        img_load = self.embedding.load_image(img)
        img_embedding = self.embedding.get_image_embedding(img_load)
        dict_similarities = self.embedding.get_similarities(img_embedding)
        assignment = np.argmax(dict_similarities, axis=0)  # argsort[0]
        tlc_image = np.unique(assignment)
        self.plot_segmentation(assignment, img_load)

    def vector_get_synset_tree(self, concept_vector):
        concept_vector = torch.from_numpy(concept_vector).view([1, 1, 1, 512]).cuda()
        dict_similarities = self.embedding.get_similarities(concept_vector)
        concept_id = np.argmax(dict_similarities.squeeze(), axis=0)
        concept = self.filtered_dict[concept_id]

        # Network of all paths from concept to 'object'
        similarity_tree = wordnet_utils.hierarchy_root_to_lemma_tree(concept, self.wn_hierarchy,
                                                                     filter_nonequal_lemmas=False)
        return similarity_tree

    def vector_to_meaning(self, concept_vector):
        k = 20
        similarity_tree = self.vector_get_synset_tree(concept_vector)
        similarity_tree = wordnet_utils.similarity_tree_visit_count_decorator(similarity_tree)

        # Sort words by similarity with concept
        concept_dict_similarity = torch.tensordot(concept_vector, torch.from_numpy(self.dict_emb).cuda(),
                                                  dims=([0], [1]))
        sorted_similarities, sorted_indices = torch.sort(concept_dict_similarity)
        sorted_similarities = torch.flip(sorted_similarities.view(1, -1), dims=[1]).flatten()
        sorted_indices = torch.flip(sorted_indices.view(1, -1), dims=[1]).flatten()
        # Update counts for first k similar concepts, then draw result
        for i in range(1, k + 1):
            new_concept_id = sorted_indices[i]
            new_concept = self.filtered_dict[new_concept_id]
            new_tree = wordnet_utils.hierarchy_root_to_lemma_tree(new_concept, self.wn_hierarchy,
                                                    filter_nonequal_lemmas=False)
            similarity_tree = wordnet_utils.similarity_tree_update_counts(similarity_tree, new_tree, new_concept)

        similarity_tree = wordnet_utils.similarity_tree_subtree_score_decorator(similarity_tree, aggregator=np.sum,
                                                                  attribute="visit_count")
        best_syn = wordnet_utils.similarity_tree_find_best_leaf(similarity_tree, self.target_synset, aggregator="depthwise_max",
                                                  similarity_attribute="subtree_score")
        return best_syn

class WordModel:

    def __init__(self, embedding: Embedding, dict_path):
        self.embedding = embedding
        self.target_synset = wn.synsets('entity', pos=wn.NOUN)[0]
        if isinstance(dict_path, str):
            dict_all = self.embedding.load_txt_dict(dict_path)
        else:
            dict_all = dict_path
        self.filtered_dict = dict_all
        self.dict_len = len(self.filtered_dict)
        self.dict_emb = embedding.get_text_embedding(self.filtered_dict).cpu().numpy()

    def get_embedding_tlcs(self, image_embedding):
        """
        Given an image embedding returns an assignment map of each pixel to the closest concept in the dictionary.
        Also returns the list of unique values in the assignment (the TLCs)
        """
        dict_similarities = self.embedding.get_similarities(image_embedding, self.dict_emb)
        assignment = np.argmax(dict_similarities, axis=0)
        tlc_image = np.unique(assignment)
        return assignment, tlc_image

    def get_image_embedding_word_mask(self, image_embedding: torch.Tensor, mask_word):
        """
        Given an embedding of an image (a volume H*W*512) and a word, returns a binary mask H*W where each element is 1
        iff the corresponding element in image_embedding is closest to mask_word than to other words in the dict.

        :param image_embedding: the image embedding as a tensor
        :param mask_word: the word on which the mask is based
        :return: a binary mask of same spatial dimension as image_embedding
        """

        word_id = self.filtered_dict.index(mask_word)
        assignment, tlc_image = self.get_embedding_tlcs(image_embedding)

        mask = np.zeros_like(assignment)
        mask[assignment == word_id] = 1

        return mask